{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4342a41e",
   "metadata": {
    "id": "G2tRwHhHuViW"
   },
   "source": [
    "\n",
    "## The following is what will be covered in this notebook (You do not need a GPU to run this notebook)\n",
    "1. Extracting sentence embeddings from pretrained BERT-like models\n",
    "2. Visualize these sentence emebddings, stacking them against each other using a distance metric i.e.\n",
    "    * Calculate distance between sentence vectors\n",
    "    * Visualize in 2D/3D the distance matrics using multi-dimensional scaling\n",
    "3. Extract word vectors from BERT-like models, and use Word Movers Distance (WMD: http://proceedings.mlr.press/v37/kusnerb15.pdf) to calculate distance between sentences\n",
    "    * Calculate distance between sentences by applying WMD\n",
    "    * Visualize in 2D/3D the distance matrics using multi-dimensional scaling\n",
    "4. Load a context specific finetuned model to understand how sentence similarity changes based on the corpus used to trian\n",
    "\n",
    "**Note: Similarity of two sentences is very subjective. Two sentences could be very similar in one context, and could mean something very different in other contexts. Let us pick sentiment as a way to evaluate these vectors. In other words, lets see how close these sentneces land up in the contexts of their sentiment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717a3017",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "9c3qiZvG8dz6",
    "outputId": "e3208486-efd5-4bf4-9b20-ac4458e70b48"
   },
   "outputs": [],
   "source": [
    "# Install libraries\n",
    "# ! pip install transformers\n",
    "# ! pip install plotly==4.9.0\n",
    "# ! pip install wmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65399791",
   "metadata": {
    "id": "yHwJT2qB8or-"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# visualization libs\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# imports\n",
    "import torch\n",
    "from scipy.spatial.distance import euclidean, pdist, squareform\n",
    "from sklearn import manifold  # use this for MDS computation\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "# Used to calculation of word movers distance between sentence\n",
    "from collections import Counter\n",
    "\n",
    "# Library to calculate Relaxed-Word Movers distance\n",
    "from wmd import WMD, libwmdrelax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159c130f",
   "metadata": {
    "id": "qYOF2W0yAion"
   },
   "outputs": [],
   "source": [
    "# Define some constants\n",
    "PRETRAINED_MODEL = \"roberta-base\"  #'bert-large-uncased'\n",
    "MAX_LEN = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c078cab9",
   "metadata": {
    "id": "7Szy2pCZw0lU"
   },
   "outputs": [],
   "source": [
    "# Initialize tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\n",
    "    PRETRAINED_MODEL\n",
    ")  # BertTokenizer.from_pretrained(PRETRAINED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88894516",
   "metadata": {
    "id": "pk4bwQ6BK7v4"
   },
   "outputs": [],
   "source": [
    "# Create a function to tokenize a set of texts\n",
    "def preprocessing_for_bert(data, tokenizer_obj, max_len=MAX_LEN):\n",
    "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
    "    @param    data (np.array): Array of texts to be processed.\n",
    "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
    "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
    "                  tokens should be attended to by the model.\n",
    "    @return   attention_masks_without_special_tok (torch.Tensor): Tensor of indices specifying which\n",
    "                  tokens should be attended to by the model excluding the special tokens (CLS/SEP)\n",
    "    \"\"\"\n",
    "    # Create empty lists to store outputs\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # For every sentence...\n",
    "    for sent in data:\n",
    "        # `encode_plus` will:\n",
    "        #    (1) Tokenize the sentence\n",
    "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
    "        #    (3) Truncate/Pad sentence to max length\n",
    "        #    (4) Map tokens to their IDs\n",
    "        #    (5) Create attention mask\n",
    "        #    (6) Return a dictionary of outputs\n",
    "        encoded_sent = tokenizer_obj.encode_plus(\n",
    "            text=sent,  # Preprocess sentence\n",
    "            add_special_tokens=True,  # Add `[CLS]` and `[SEP]`\n",
    "            max_length=max_len,  # Max length to truncate/pad\n",
    "            pad_to_max_length=True,  # Pad sentence to max length\n",
    "            truncation=True,  # Truncate longer seq to max_len\n",
    "            return_attention_mask=True,  # Return attention mask\n",
    "        )\n",
    "\n",
    "        # Add the outputs to the lists\n",
    "        input_ids.append(encoded_sent.get(\"input_ids\"))\n",
    "        attention_masks.append(encoded_sent.get(\"attention_mask\"))\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    # lets create another mask that will be useful when we want to average all word vectors later\n",
    "    # we would like to average across all word vectors in a sentence, but excluding the CLS and SEP token\n",
    "    # create a copy\n",
    "    attention_masks_without_special_tok = attention_masks.clone().detach()\n",
    "\n",
    "    # set the CLS token index to 0 for all sentences\n",
    "    attention_masks_without_special_tok[:, 0] = 0\n",
    "\n",
    "    # get sentence lengths and use that to set those indices to 0 for each length\n",
    "    # essentially, the last index for each sentence, which is the SEP token\n",
    "    sent_len = attention_masks_without_special_tok.sum(1).tolist()\n",
    "\n",
    "    # column indices to set to zero\n",
    "    col_idx = torch.LongTensor(sent_len)\n",
    "    # row indices for all rows\n",
    "    row_idx = torch.arange(attention_masks.size(0)).long()\n",
    "\n",
    "    # set the SEP indices for each sentence token to zero\n",
    "    attention_masks_without_special_tok[row_idx, col_idx] = 0\n",
    "\n",
    "    return input_ids, attention_masks, attention_masks_without_special_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105c40c5",
   "metadata": {
    "id": "ppthffJg8uWx"
   },
   "outputs": [],
   "source": [
    "# initialize model\n",
    "# output_hidden_states = True will give us all hiddenn states for all layers\n",
    "pretrained_model = RobertaModel.from_pretrained(\n",
    "    PRETRAINED_MODEL, output_hidden_states=True\n",
    ")\n",
    "# put this in eval mode so since we do not plan to do backprop\n",
    "pretrained_model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf57fa0",
   "metadata": {
    "id": "LweRgwZJJf9Z"
   },
   "source": [
    "# The data\n",
    "We pick Four sentences -\n",
    "  * Two from the IMDB 50k movie reviews dataset (ensuring we dont pick from the training set we eventually use to finetune)\n",
    "  * Two from a a dataset from a completely different domain, Amazon fine food reviews dataset\n",
    "\n",
    "The idea is to stack these 4 random sentences against each other, both from the base pretrained models, and from a finetuned model. This will allow us to evaluate if the model that is finetuned becomes biased towards the sentiment, shedding some of its understanding of other forms of those words/sentences \n",
    "\n",
    "You can download these datasets from here:\n",
    "\n",
    "https://www.kaggle.com/snap/amazon-fine-food-reviews\n",
    "\n",
    "https://www.kaggle.com/atulanandjha/imdb-50k-movie-reviews-test-your-bert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac3ca02",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "8zuNfJSNBFzT",
    "outputId": "f74cfa2b-572d-4271-b764-0e1fa70ff03e"
   },
   "outputs": [],
   "source": [
    "### Lets pick the sentences that we would run through and visualize distance/similarity\n",
    "# List of tupes :\n",
    "# (sentence, label_id)\n",
    "# label_id == 0 == negative\n",
    "# label_id == 1 == positive\n",
    "\n",
    "sents_and_labs = [\n",
    "    (\n",
    "        \"This taffy is so good.  It is very soft and chewy.  The flavors are amazing.  I would definitely recommend you buying it.  Very satisfying!!\",\n",
    "        1,\n",
    "    ),\n",
    "    # ('This is a good film. This is very funny. Yet after this film there were no good Ernest films!', 1),\n",
    "    (\n",
    "        \"Just love the interplay between two great characters of stage & screen - Veidt & Barrymore\",\n",
    "        1,\n",
    "    ),\n",
    "    (\n",
    "        \"Hated it with all my being. Worst movie ever. Mentally- scarred. Help me. It was that bad.TRUST ME!!!\",\n",
    "        0,\n",
    "    ),\n",
    "    (\n",
    "        \"This oatmeal is not good. Its mushy, soft, I don't like it. Quaker Oats is the way to go.\",\n",
    "        0,\n",
    "    ),\n",
    "]\n",
    "\n",
    "sents = [s for s, l in sents_and_labs]\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29e334b",
   "metadata": {
    "id": "UoDwTOd7MqDm"
   },
   "outputs": [],
   "source": [
    "def get_preds(sentences, tokenizer_obj, model_obj):\n",
    "    \"\"\"\n",
    "    Quick function to extract hidden states and masks from the sentences and model passed\n",
    "    \"\"\"\n",
    "    # Run the sentences through tokenizer\n",
    "    input_ids, att_msks, attention_masks_wo_special_tok = preprocessing_for_bert(\n",
    "        sentences, tokenizer_obj\n",
    "    )\n",
    "    # Run the sentences through the model\n",
    "    outputs = model_obj(input_ids, att_msks)\n",
    "\n",
    "    # Lengths of each sentence\n",
    "    sent_lens = att_msks.sum(1).tolist()\n",
    "\n",
    "    # calculate unique vocab\n",
    "    # #get the tokenized version of each sentence (text form, to label things in the plot)\n",
    "    tokenized_sents = [tokenizer_obj.convert_ids_to_tokens(i) for i in input_ids]\n",
    "    return {\n",
    "        \"hidden_states\": outputs[2],\n",
    "        \"pooled_output\": outputs[1],\n",
    "        \"attention_masks\": att_msks,\n",
    "        \"attention_masks_without_special_tok\": attention_masks_wo_special_tok,\n",
    "        \"tokenized_sents\": tokenized_sents,\n",
    "        \"sentences\": sentences,\n",
    "        \"sent_lengths\": sent_lens,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50a42ca",
   "metadata": {
    "id": "_jYPazcIPI0j"
   },
   "outputs": [],
   "source": [
    "pretrained_preds = get_preds(sents, tokenizer, pretrained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240913df",
   "metadata": {
    "id": "-RL5XURetaYw"
   },
   "source": [
    "## Let's get sentence embedding and visualize using cosine distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7ad6c5",
   "metadata": {
    "id": "uzTlpG4XPe2l"
   },
   "source": [
    "###### Left the below code in there which helped me understand how to apply a 2D mast to a 3d tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05d9516",
   "metadata": {
    "id": "qeMfCvbG7yPL"
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/61956893/how-to-mask-a-3d-tensor-with-2d-mask-and-keep-the-dimensions-of-original-vector\n",
    "# example to apply a 2d mask to the 3d tensor\n",
    "# X = torch.arange(24).view(4, 3, 2)\n",
    "# print(X)\n",
    "\n",
    "# mask = torch.zeros((4, 3), dtype=torch.int64)  # or dtype=torch.ByteTensor\n",
    "# mask[0, 0] = 1\n",
    "# mask[1, 1] = 1\n",
    "# mask[3, 0] = 1\n",
    "# print('Mask: ', mask)\n",
    "\n",
    "# # Add a dimension to the mask tensor and expand it to the size of original tensor\n",
    "# mask_ = mask.unsqueeze(-1).expand(X.size())\n",
    "# print(mask_)\n",
    "\n",
    "# # Select based on the new expanded mask\n",
    "# Y = X * mask_\n",
    "# print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4dc153",
   "metadata": {
    "id": "aqC-PSqxzOzC"
   },
   "outputs": [],
   "source": [
    "def plt_dists(\n",
    "    dists,\n",
    "    sentences_and_labels,\n",
    "    dims=2,\n",
    "    title=\"\",\n",
    "    xrange=[-0.5, 0.5],\n",
    "    yrange=[-0.5, 0.5],\n",
    "    zrange=[-0.5, 0.5],\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot distances using MDS in 2D/3D\n",
    "    dists: precomputed distance matrix\n",
    "    sentences_and_labels: tuples of sentence and label_ids\n",
    "    dims: 2/3 for 2 or 3 dimensional plot, defaults to 2 for any other value passed\n",
    "    words_of_interest: list of words to highlight with a different color\n",
    "    title: title for the plot\n",
    "    \"\"\"\n",
    "    # get the sentence text and labels to pass to the plot\n",
    "    sents, color = zip(*sentences_and_labels)\n",
    "\n",
    "    # https://community.plotly.com/t/plotly-colours-list/11730/6\n",
    "    colorscale = [\n",
    "        [0, \"deeppink\"],\n",
    "        [1, \"yellow\"],\n",
    "    ]  # , [2, 'greens'], [3, 'reds'], [4, 'blues']]\n",
    "\n",
    "    # dists is precomputed using cosine similarity/other other metric and passed\n",
    "    # calculate MDS with number of dims passed\n",
    "    mds = manifold.MDS(\n",
    "        n_components=dims, dissimilarity=\"precomputed\", random_state=60, max_iter=90000\n",
    "    )\n",
    "    results = mds.fit(dists)\n",
    "\n",
    "    # get coodinates for each point\n",
    "    coords = results.embedding_\n",
    "\n",
    "    # plot 3d/2d\n",
    "    if dims == 3:\n",
    "        fig = go.Figure(\n",
    "            data=[\n",
    "                go.Scatter3d(\n",
    "                    x=coords[:, 0],\n",
    "                    y=coords[:, 1],\n",
    "                    z=coords[:, 2],\n",
    "                    mode=\"markers+text\",\n",
    "                    textposition=\"top center\",\n",
    "                    text=sents,\n",
    "                    marker=dict(\n",
    "                        size=12, color=color, colorscale=colorscale, opacity=0.8\n",
    "                    ),\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        fig = go.Figure(\n",
    "            data=[\n",
    "                go.Scatter(\n",
    "                    x=coords[:, 0],\n",
    "                    y=coords[:, 1],\n",
    "                    text=sents,\n",
    "                    textposition=\"top center\",\n",
    "                    mode=\"markers+text\",\n",
    "                    marker=dict(\n",
    "                        size=12, color=color, colorscale=colorscale, opacity=0.8\n",
    "                    ),\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    fig.update_layout(template=\"plotly_dark\")\n",
    "    if title != \"\":\n",
    "        fig.update_layout(title_text=title)\n",
    "        fig.update_layout(\n",
    "            titlefont=dict(\n",
    "                family=\"Courier New, monospace\", size=14, color=\"cornflowerblue\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # update the axes ranges\n",
    "    fig.update_layout(yaxis=dict(range=yrange))\n",
    "    fig.update_layout(xaxis=dict(range=xrange))\n",
    "    fig.update_traces(textfont_size=10)\n",
    "\n",
    "    # TO DO: fix this. I could not get this to work. somehow the library does not like the zaxis.\n",
    "    # if dims==3:\n",
    "    # fig.update_layout(zaxis=dict(range=zrange))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53d2976",
   "metadata": {
    "id": "fkR5kYvh_ff4"
   },
   "outputs": [],
   "source": [
    "def get_word_vectors(\n",
    "    hidden_layers_form_arch, token_index=None, mode=\"average\", top_n_layers=4\n",
    "):\n",
    "    \"\"\"\n",
    "    retrieve vectors for all tokens from the top n layers and return a concatenated, averaged or summed vector\n",
    "    hidden_layers_form_arch: tuple returned by the transformer library\n",
    "    token_index: None/Index:\n",
    "      If None: Returns all the tokens\n",
    "      If Index: Returns vectors for that index in each sentence\n",
    "\n",
    "    mode=\n",
    "          'average' : avg last n layers\n",
    "          'concat': concatenate last n layers\n",
    "          'sum' : sum last n layers\n",
    "          'last': return embeddings only from last layer\n",
    "          'second_last': return embeddings only from second last layer\n",
    "\n",
    "    top_n_layers: number of top layers to concatenate/ average / sum\n",
    "    \"\"\"\n",
    "\n",
    "    vecs = None\n",
    "    if mode == \"concat\":\n",
    "        vecs = torch.cat(hidden_layers_form_arch[-top_n_layers:], dim=2)\n",
    "\n",
    "    if mode == \"average\":\n",
    "        vecs = torch.stack(hidden_layers_form_arch[-top_n_layers:]).mean(0)\n",
    "\n",
    "    if mode == \"sum\":\n",
    "        vecs = torch.stack(hidden_layers_form_arch[-top_n_layers:]).sum(0)\n",
    "\n",
    "    if mode == \"last\":\n",
    "        vecs = hidden_layers_form_arch[-1:][0]\n",
    "\n",
    "    if mode == \"second_last\":\n",
    "        vecs = hidden_layers_form_arch[-2:-1][0]\n",
    "\n",
    "    if vecs is not None and token_index:\n",
    "        # if a token index is passed, return values for a particular index in the sequence instead of vectors for all\n",
    "        return vecs.permute(1, 0, 2)[token_index]\n",
    "    return vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f97b51d",
   "metadata": {
    "id": "Ts8sYipWC5tR"
   },
   "outputs": [],
   "source": [
    "def get_sent_vectors(input_states, att_mask):\n",
    "    \"\"\"\n",
    "    get a sentence vector by averaging over all word vectors -> this could come from any layers or averaged themselves (see get_all_token_vectors function)\n",
    "    input_states: [batch_size x seq_len x vector_dims] -> e.g. output from  hidden stats from a particular layer\n",
    "    att_mask: attention mask passed should have already maseked the special tokens too i.e. CLS/SEP/<s>/special tokens masked out with 0 -> [batch_size x max_seq_length]\n",
    "    ref: https://stackoverflow.com/questions/61956893/how-to-mask-a-3d-tensor-with-2d-mask-and-keep-the-dimensions-of-original-vector\n",
    "    \"\"\"\n",
    "\n",
    "    # print(input_states.shape) #-> [batch_size x seq_len x vector_dim]\n",
    "\n",
    "    # Let's get sentence lengths for each sentence\n",
    "    sent_lengths = att_mask.sum(\n",
    "        1\n",
    "    )  # att_mask has a 1 against each valid token and 0 otherwise\n",
    "\n",
    "    # create a new 3rd dim and broadcast the attention mask across it -> this will allow us to use this mask with the 3d tensor input_hidden_states\n",
    "    att_mask_ = att_mask.unsqueeze(-1).expand(input_states.size())\n",
    "\n",
    "    # use mask to 0 out all the values against special tokens like CLS, SEP , <s> using mask\n",
    "    masked_states = input_states * att_mask_\n",
    "\n",
    "    # calculate average\n",
    "    sums = masked_states.sum(1)\n",
    "    avg = sums / sent_lengths[:, None]\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26544938",
   "metadata": {
    "id": "lX-B9Qu1RFuT"
   },
   "outputs": [],
   "source": [
    "def eval_vectors(\n",
    "    model_output,\n",
    "    sentences_and_labels,\n",
    "    wrd_vec_mode=\"concat\",\n",
    "    wrd_vec_top_n_layers=4,\n",
    "    viz_dims=2,\n",
    "    sentence_emb_mode=\"average_word_vectors\",\n",
    "    title_prefix=None,\n",
    "    plt_xrange=[-0.05, 0.05],\n",
    "    plt_yrange=[-0.05, 0.05],\n",
    "    plt_zrange=[-0.05, 0.05],\n",
    "):\n",
    "    \"\"\"\n",
    "    Get vectors for all sentences and visualize them based on cosine distance between them\n",
    "\n",
    "    model_output: model output extracted as a dictionary from get_preds function\n",
    "    sentences_and_labels: tuple of sentence and labels_ids\n",
    "    att_msk: attention mask that also marks the special tokens (CLS/SEP etc.) as 0\n",
    "    mode=\n",
    "          'average' : avg last n layers\n",
    "          'concat': concatenate last n layers\n",
    "          'sum' : sum last n layers\n",
    "          'last': return embeddings only from last layer\n",
    "          'second_last': return embeddings only from second last layer\n",
    "    viz_dims:2/3 for 2D/3D plot\n",
    "    title_prefix: String to add before the descriptive title. Can be used to add model name etc.\n",
    "    \"\"\"\n",
    "    title_wrd_emv = \"{} across {} layers\".format(wrd_vec_mode, wrd_vec_top_n_layers)\n",
    "\n",
    "    # get word vectors for all words in the sentence\n",
    "    if sentence_emb_mode == \"average_word_vectors\":\n",
    "        title_sent_emb = (\n",
    "            \"average(word vectors in the sentence); Sentence Distance: Cosine\"\n",
    "        )\n",
    "        word_vecs_across_sent = get_word_vectors(\n",
    "            model_output[\"hidden_states\"],\n",
    "            mode=wrd_vec_mode,\n",
    "            token_index=None,\n",
    "            top_n_layers=wrd_vec_top_n_layers,\n",
    "        )  # returns [batch_size x seq_len x vector_dim]\n",
    "        sent_vecs = get_sent_vectors(\n",
    "            word_vecs_across_sent, model_output[\"attention_masks_without_special_tok\"]\n",
    "        )\n",
    "    else:\n",
    "        title_sent_emb = \"First tok (CLS) vector; Sentence Distance: Cosine\"\n",
    "        # Get the pooled output from the first token (e.g. CLS token in case of BERT)\n",
    "\n",
    "        # Note from https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "        # This output is usually not a good summary of the semantic content of the\n",
    "        # input, youâ€™re often better with averaging or\n",
    "        # pooling the sequence of hidden-states for the whole input sequence.\n",
    "        print(\"inside\")\n",
    "        sent_vecs = model_output[\"pooled_output\"]  # vector\n",
    "\n",
    "    if title_prefix:\n",
    "        final_title = \"{} Word Vec: {}; Sentence Vector: {}\".format(\n",
    "            title_prefix, title_wrd_emv, title_sent_emb\n",
    "        )\n",
    "    else:\n",
    "        final_title = \"Word Vec: {}; Sentence Vector: {}\".format(\n",
    "            title_wrd_emv, title_sent_emb\n",
    "        )\n",
    "    mat = sent_vecs.detach().numpy()\n",
    "    plt_dists(\n",
    "        cosine_distances(mat),\n",
    "        sentences_and_labels=sentences_and_labels,\n",
    "        dims=viz_dims,\n",
    "        title=final_title,\n",
    "        xrange=plt_xrange,\n",
    "        yrange=plt_yrange,\n",
    "        zrange=plt_zrange,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d424e7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "OjHGcFXcSE4-",
    "outputId": "a84a7a60-90ae-4bc4-fe00-fd0bdca2a2d6"
   },
   "outputs": [],
   "source": [
    "eval_vectors(\n",
    "    pretrained_preds,\n",
    "    sents_and_labs,\n",
    "    wrd_vec_mode=\"concat\",\n",
    "    sentence_emb_mode=\"average_word_vectors\",\n",
    "    plt_xrange=[-0.03, 0.03],\n",
    "    plt_yrange=[-0.03, 0.03],\n",
    "    title_prefix=\"Pretrained model:\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7c0873",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "id": "J5BFkJQQu1QF",
    "outputId": "a78a303e-f6a1-4cba-cd26-6a0fc6143abb"
   },
   "outputs": [],
   "source": [
    "eval_vectors(\n",
    "    pretrained_preds,\n",
    "    sents_and_labs,\n",
    "    wrd_vec_mode=\"concat\",\n",
    "    sentence_emb_mode=\"pooled_output\",\n",
    "    plt_xrange=[-0.03, 0.03],\n",
    "    plt_yrange=[-0.03, 0.03],\n",
    "    title_prefix=\"Pretrained model:\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ba27e7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "C8YI2sI3Scik",
    "outputId": "41c22d37-4271-428d-a653-fa6227bd2a1a"
   },
   "outputs": [],
   "source": [
    "eval_vectors(\n",
    "    pretrained_preds,\n",
    "    sents_and_labs,\n",
    "    wrd_vec_mode=\"average\",\n",
    "    sentence_emb_mode=\"average_word_vectors\",\n",
    "    title_prefix=\"Pretrained model:\",\n",
    "    plt_xrange=[-0.03, 0.03],\n",
    "    plt_yrange=[-0.03, 0.03],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cb9ce9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "42F1buwbScnH",
    "outputId": "2fd2c213-ee15-4248-e2f0-2d4ab2680d00"
   },
   "outputs": [],
   "source": [
    "eval_vectors(\n",
    "    pretrained_preds,\n",
    "    sents_and_labs,\n",
    "    wrd_vec_mode=\"second_last\",\n",
    "    sentence_emb_mode=\"average_word_vectors\",\n",
    "    plt_xrange=[-0.03, 0.04],\n",
    "    plt_yrange=[-0.03, 0.03],\n",
    "    title_prefix=\"Pretrained model:\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c568fa4",
   "metadata": {
    "id": "RU5VR3fJhySt"
   },
   "source": [
    "## Let's do the same, but this time with Word Movers Distance\n",
    "1. Link to the paper: http://www.cs.cornell.edu/~kilian/papers/wmd_metric.pdf\n",
    "2. Implementation being modified from https://github.com/src-d/wmd-relax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55b6541",
   "metadata": {
    "id": "QyG_iWIEDIel"
   },
   "outputs": [],
   "source": [
    "def get_vector_for_each_token_position(\n",
    "    hidden_layers_form_arch, token_index=0, mode=\"average\", top_n_layers=4\n",
    "):\n",
    "    \"\"\"\n",
    "    retrieve vectors for a token_index from the top n layers and return a concatenated, averaged or summed vector\n",
    "    hidden_layers_form_arch: tuple returned by the transformer library\n",
    "    token_index: index of the token for which a vector is desired\n",
    "    mode=\n",
    "          'average' : avg last n layers\n",
    "          'concat': concatenate last n layers\n",
    "          'sum' : sum last n layers\n",
    "          'last': return embeddings only from last layer\n",
    "          'second_last': return embeddings only from second last layer\n",
    "\n",
    "    top_n_layers: number of top layers to concatenate/ average / sum\n",
    "    \"\"\"\n",
    "    if mode == \"concat\":\n",
    "        # concatenate last 4 layer outputs -> returns [batch_size x seq_len x dim]\n",
    "        # permute(1,0,2) swaps the the batch and seq_len dim , making it easy to return all the vectors for a particular token position\n",
    "        return torch.cat(hidden_layers_form_arch[-top_n_layers:], dim=2).permute(\n",
    "            1, 0, 2\n",
    "        )[token_index]\n",
    "\n",
    "    if mode == \"average\":\n",
    "        # avg last 4 layer outputs -> returns [batch_size x seq_len x dim]\n",
    "        return (\n",
    "            torch.stack(hidden_layers_form_arch[-top_n_layers:])\n",
    "            .mean(0)\n",
    "            .permute(1, 0, 2)[token_index]\n",
    "        )\n",
    "\n",
    "    if mode == \"sum\":\n",
    "        # sum last 4 layer outputs -> returns [batch_size x seq_len x dim]\n",
    "        return (\n",
    "            torch.stack(hidden_layers_form_arch[-top_n_layers:])\n",
    "            .sum(0)\n",
    "            .permute(1, 0, 2)[token_index]\n",
    "        )\n",
    "\n",
    "    if mode == \"last\":\n",
    "        # last layer output -> returns [batch_size x seq_len x dim]\n",
    "        return hidden_layers_form_arch[-1:][0].permute(1, 0, 2)[token_index]\n",
    "\n",
    "    if mode == \"second_last\":\n",
    "        # last layer output -> returns [batch_size x seq_len x dim]\n",
    "        return hidden_layers_form_arch[-2:-1][0].permute(1, 0, 2)[token_index]\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d5137c",
   "metadata": {
    "id": "CI2I5ShIhxai"
   },
   "outputs": [],
   "source": [
    "def build_word_embedding_lookup(\n",
    "    model_output, wrd_vec_mode=\"concat\", top_n_layers=4, max_len=MAX_LEN\n",
    "):\n",
    "    \"\"\"\n",
    "    build a embedding lookup - this will be needed when we do need to pull up vectors for any word while calculating wmd\n",
    "    model_output: model output extracted as a dictionary from get_preds function; should include 'hidden_states', 'tokenized_sents', 'sent_lengths'\n",
    "    wrd_vec_mode: concat/average/sum/last/second_last - way to extract word embeddings from the architecture\n",
    "    top_n_layers: number of layers to work on to get word vectors using the wrd_vec_mode\n",
    "    max_len: max length of the sentence for the architecture\n",
    "    returns:\n",
    "      vecs: a dict with keys as tokens and sentence number (e.g. date in sent 0 becomes date_0), and values as vectors extracted from bert like models\n",
    "      documents: dictionary with sentence number as key and tokens like date_0 joined with a space as a string\n",
    "    \"\"\"\n",
    "    vecs = dict()\n",
    "    documents = dict()\n",
    "\n",
    "    for token_ind in range(max_len):\n",
    "        if token_ind == 0:\n",
    "            # ignore CLS\n",
    "            continue\n",
    "\n",
    "        vectors = get_vector_for_each_token_position(\n",
    "            model_output[\"hidden_states\"],\n",
    "            token_index=token_ind,\n",
    "            mode=wrd_vec_mode,\n",
    "            top_n_layers=top_n_layers,\n",
    "        )\n",
    "        for sent_ind, sent_len in enumerate(model_output[\"sent_lengths\"]):\n",
    "            if token_ind < sent_len - 1:  # ignore SEP which will be at sent_len-1 index\n",
    "                txt = (\n",
    "                    model_output[\"tokenized_sents\"][sent_ind][token_ind]\n",
    "                    + \"_\"\n",
    "                    + str(sent_ind)\n",
    "                )\n",
    "\n",
    "                # store the token and its vector -> this will be our lookup storage for vectors\n",
    "                vecs[txt] = vectors[sent_ind].detach().numpy()\n",
    "\n",
    "                # store this so that we can do comparisons\n",
    "                if sent_ind not in documents:\n",
    "                    documents[sent_ind] = txt\n",
    "                else:\n",
    "                    documents[sent_ind] += \" \" + txt\n",
    "    return vecs, documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0a9892",
   "metadata": {
    "id": "8xpVQMxeAd48"
   },
   "outputs": [],
   "source": [
    "# Modified from https://github.com/src-d/wmd-relax/blob/master/wmd/__init__.py\n",
    "# class to extract and calculate word movers distance using bert\n",
    "class SimilarityWMD(object):\n",
    "    def __init__(self, embedding_dict, sklearn_euclidean_distances=True, **kwargs):\n",
    "        \"\"\"\n",
    "        :param embedding_dict: a dictionary to look up vectors \n",
    "        :param only_alpha: Indicates whether only alpha tokens must be used.\n",
    "        :param frequency_processor: The function which is applied to raw \\\n",
    "                                    token frequencies.\n",
    "\n",
    "        :type frequency_processor: callable\n",
    "        \"\"\"\n",
    "\n",
    "        self.frequency_processor = kwargs.get(\n",
    "            \"frequency_processor\", lambda t, f: np.log(1 + f)\n",
    "        )\n",
    "        self.embedding_dict = embedding_dict\n",
    "        # get embed size\n",
    "        self.emb_size = self.embedding_dict[next(iter(self.embedding_dict))].shape[0]\n",
    "        self.sklearn_euclidean_distances = sklearn_euclidean_distances\n",
    "\n",
    "    def _get_normalized_item(self, item):\n",
    "        \"\"\"\n",
    "        get id and find a vector for the corresponding id in the embedding lookup\n",
    "        \"\"\"\n",
    "        v = self.embedding_dict[item]\n",
    "        return v / v.sum()\n",
    "\n",
    "    def _dist_fn(self, u, v):\n",
    "        return libwmdrelax.emd(u, v, self.dists)\n",
    "\n",
    "    def _calc_euclidean_distances(self, evec):\n",
    "        if self.sklearn_euclidean_distances:\n",
    "            # call sklearn.metrics.pairwise.euclidean_distances\n",
    "            return euclidean_distances(evec)\n",
    "\n",
    "        evec_sqr = (evec * evec).sum(axis=1)\n",
    "        dists = evec_sqr - 2 * evec.dot(evec.T) + evec_sqr[:, np.newaxis]\n",
    "        dists[dists < 0] = 0\n",
    "        dists = np.sqrt(dists)\n",
    "        for i in range(len(dists)):\n",
    "            dists[i, i] = 0\n",
    "        return dists\n",
    "\n",
    "    def compute_similarity(self, docs):\n",
    "        \"\"\"\n",
    "        Calculates the similarity between two spaCy documents. Extracts the\n",
    "        nBOW from them and evaluates the WMD.\n",
    "        :return: The calculated similarity.\n",
    "        :rtype: float.\n",
    "        \"\"\"\n",
    "\n",
    "        # {'word1': 0.6931471805599453,...}\n",
    "        # generates word -> freq mapping for each doc\n",
    "        docs_nbow = [self._convert_document(d) for d in docs]\n",
    "\n",
    "        # get vocab with indices for each\n",
    "        # {239326000841: 0, 286393583696: 1, ...}\n",
    "        vocabulary = set()\n",
    "        for distribution in docs_nbow:\n",
    "            vocabulary = vocabulary.union(set(distribution))\n",
    "\n",
    "        vocabulary = {w: i for i, w in enumerate(sorted(vocabulary))}\n",
    "\n",
    "        \"\"\"\n",
    "        #generate nbow\n",
    "        e.g.\n",
    "        [0.14285715 0.14285715 0.         0.         0.         0.\n",
    "        0.14285715 0.14285715 0.         0.14285715 0.         0.14285715\n",
    "        0.         0.14285715]\n",
    "        \"\"\"\n",
    "        weights = list()\n",
    "        for d in docs_nbow:\n",
    "            weights.append(self._generate_weights(d, vocabulary))\n",
    "\n",
    "        evec = np.zeros((len(vocabulary), self.emb_size), dtype=np.float32)\n",
    "\n",
    "        for w, i in vocabulary.items():\n",
    "            evec[i] = self._get_normalized_item(w)\n",
    "\n",
    "        # calculate euclidean_distances between all pairs of vectors\n",
    "        self.dists = self._calc_euclidean_distances(evec)\n",
    "\n",
    "        # calculate word movers distance for all our sentences\n",
    "        wmd_dists = pdist(weights, self._dist_fn)\n",
    "\n",
    "        # return a datafrrame NxN (N = number of sentences) with distances between each pair\n",
    "        # return pd.DataFrame(squareform(wmd_dists), index=docs, columns=docs)\n",
    "        return squareform(wmd_dists)\n",
    "\n",
    "    def _convert_document(self, doc):\n",
    "        wrds = defaultdict(int)\n",
    "        for t in doc.split():\n",
    "            wrds[t] += 1\n",
    "        return {t: self.frequency_processor(t, v) for t, v in wrds.items()}\n",
    "\n",
    "    def _generate_weights(self, doc, vocabulary):\n",
    "        w = np.zeros(len(vocabulary), dtype=np.float32)\n",
    "        for t, v in doc.items():\n",
    "            w[vocabulary[t]] = v\n",
    "        w /= w.sum()\n",
    "        return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4f14b0",
   "metadata": {
    "id": "bzBQZiR52nbo"
   },
   "outputs": [],
   "source": [
    "def eval_using_wmd(\n",
    "    model_output,\n",
    "    sentences_and_labels,\n",
    "    wrd_vec_mode=\"concat\",\n",
    "    viz_dims=2,\n",
    "    wrd_vec_top_n_layers=4,\n",
    "    title_prefix=None,\n",
    "    plt_xrange=[-0.03, 0.03],\n",
    "    plt_yrange=[-0.03, 0.03],\n",
    "    plt_zrange=[-0.05, 0.05],\n",
    "):\n",
    "    \"\"\"\n",
    "    model_output: model output extracted as a dictionary from get_preds function\n",
    "    sentences_and_labels: tuple of sentence and labels_ids\n",
    "    wrd_vec_top_n_layers: number of layers to use while extracting word embeddings\n",
    "    wrd_vec_mode=\n",
    "          'average' : avg last n layers\n",
    "          'concat': concatenate last n layers\n",
    "          'sum' : sum last n layers\n",
    "          'last': return embeddings only from last layer\n",
    "          'second_last': return embeddings only from second last layer\n",
    "    viz_dims:2/3 for 2D/3D plot\n",
    "    title_prefix: String to add before the descriptive title. Can be used to add model name etc.\n",
    "    \"\"\"\n",
    "    # get all vectors for all words in each sentence\n",
    "    vecs, documents = build_word_embedding_lookup(\n",
    "        model_output, wrd_vec_mode=wrd_vec_mode, top_n_layers=wrd_vec_top_n_layers\n",
    "    )\n",
    "\n",
    "    # calculate the word movers distance\n",
    "    dist_matrix = SimilarityWMD(vecs).compute_similarity(\n",
    "        [documents[i] for i in range(len(documents))]\n",
    "    )\n",
    "\n",
    "    title_wrd_emv = \"{} across {} layers\".format(wrd_vec_mode, wrd_vec_top_n_layers)\n",
    "\n",
    "    if title_prefix:\n",
    "        final_title = \"{} Word Vec: {}; Sentence Distance: Word Movers Distance\".format(\n",
    "            title_prefix, title_wrd_emv\n",
    "        )\n",
    "    else:\n",
    "        final_title = \"Word Vec: {}; Sentence Distance: Word Movers Distance\".format(\n",
    "            title_wrd_emv\n",
    "        )\n",
    "\n",
    "    # plot distances\n",
    "    plt_dists(\n",
    "        dist_matrix,\n",
    "        sentences_and_labels=sentences_and_labels,\n",
    "        dims=viz_dims,\n",
    "        title=final_title,\n",
    "        xrange=plt_xrange,\n",
    "        yrange=plt_yrange,\n",
    "        zrange=plt_zrange,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d35d4e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "XGO87C5DZLM_",
    "outputId": "d07dda9f-0c5d-4d20-e049-e44e32ee17ff"
   },
   "outputs": [],
   "source": [
    "eval_using_wmd(\n",
    "    pretrained_preds,\n",
    "    sents_and_labs,\n",
    "    wrd_vec_mode=\"concat\",\n",
    "    plt_xrange=[-0.4, 0.4],\n",
    "    plt_yrange=[-0.4, 0.4],\n",
    "    title_prefix=\"Pretrained model:\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c443754b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "D43jsOdA4x1e",
    "outputId": "e2b6a028-621d-44b8-ab94-d653174a35b4"
   },
   "outputs": [],
   "source": [
    "eval_using_wmd(\n",
    "    pretrained_preds,\n",
    "    sents_and_labs,\n",
    "    wrd_vec_mode=\"average\",\n",
    "    plt_xrange=[-0.4, 0.4],\n",
    "    plt_yrange=[-0.4, 0.4],\n",
    "    title_prefix=\"Pretrained model:\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f514d5b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "9V3Z8wlJ8L90",
    "outputId": "16154b93-4808-4ca3-a879-d1c0b1dc86a5"
   },
   "outputs": [],
   "source": [
    "eval_using_wmd(\n",
    "    pretrained_preds,\n",
    "    sents_and_labs,\n",
    "    wrd_vec_mode=\"second_last\",\n",
    "    plt_xrange=[-0.4, 0.4],\n",
    "    plt_yrange=[-0.4, 0.4],\n",
    "    title_prefix=\"Pretrained model:\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09685876",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "kNyKoaMtZnSV",
    "outputId": "d8795f11-cb89-47b6-cc68-694a07215a02"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7be475",
   "metadata": {
    "id": "IrHcz6DoiTDD"
   },
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "\n",
    "\n",
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, n_classes, bertmodel, dropout_p=0.3):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.bert = bertmodel\n",
    "        self.dropout = nn.Dropout(p=dropout_p)\n",
    "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        last_hidden_state, pooled_output = self.bert(\n",
    "            input_ids=input_ids, attention_mask=attention_mask\n",
    "        )\n",
    "        output = self.dropout(pooled_output)\n",
    "        return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e435fc47",
   "metadata": {
    "id": "DNGko-PTiwsH"
   },
   "outputs": [],
   "source": [
    "# PRE_TRAINED_MODEL_NAME = 'roberta-base'\n",
    "finetuned_model = RobertaModel.from_pretrained(\n",
    "    PRETRAINED_MODEL, output_hidden_states=True\n",
    ")\n",
    "# put this in eval mode so since we do not plan to do backprop and also any other special handling that it needs to do like dropout\n",
    "finetuned_model.eval()\n",
    "senti_model = SentimentClassifier(len([\"neg\", \"pos\"]), bertmodel=finetuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2bc887",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "pi790ArGhPZ9",
    "outputId": "8ca20835-7271-4003-ec2d-80d82999efc7"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "from torch import nn, optim\n",
    "\n",
    "MODEL_SAVE_NAME = \"imdb_movie_large_roberta_state\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    map_location = lambda storage, loc: storage.cuda()\n",
    "else:\n",
    "    map_location = \"cpu\"\n",
    "\n",
    "state_file_name = sorted(\n",
    "    list(\n",
    "        glob.glob(\n",
    "            \"/content/drive/My Drive/Datasets/IMDBMovieReviews/{}*\".format(\n",
    "                MODEL_SAVE_NAME\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")[-1]\n",
    "print(\"Loading : {}\".format(state_file_name))\n",
    "state = torch.load(state_file_name, map_location=map_location)\n",
    "senti_model.load_state_dict(state[\"model\"])\n",
    "state = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56b63c5",
   "metadata": {
    "id": "453Ks67U8sTx"
   },
   "outputs": [],
   "source": [
    "finetuned_preds = get_preds(sents, tokenizer, senti_model.bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df04ca3",
   "metadata": {
    "id": "04er42bJ92U-"
   },
   "source": [
    "# Comparing models Pretrained (out-of-the-box) vs fine-tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e6a67e",
   "metadata": {
    "id": "WCPs7O_k95C-"
   },
   "source": [
    "## 1. Run with config : \n",
    "* word vec average across 4 layers \n",
    "* sentence vectors obtained from averaging across all word embeddings in the sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4178342c",
   "metadata": {
    "id": "6spdgrJZ-JAj"
   },
   "source": [
    "### 1.1 Pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cc021a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "qxKjH2bL9IQD",
    "outputId": "6a8f183e-a34c-4cfa-81d0-c9b3f182c019"
   },
   "outputs": [],
   "source": [
    "eval_vectors(\n",
    "    pretrained_preds,\n",
    "    sents_and_labs,\n",
    "    wrd_vec_mode=\"average\",\n",
    "    sentence_emb_mode=\"average_word_vectors\",\n",
    "    plt_xrange=[-0.03, 0.03],\n",
    "    plt_yrange=[-0.03, 0.03],\n",
    "    viz_dims=2,\n",
    "    title_prefix=\"Pretrained Model:\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785d2d13",
   "metadata": {
    "id": "RYMQW95v-LzM"
   },
   "source": [
    "### 1.2 Fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789da672",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "aUuMud-g9IU6",
    "outputId": "457a2d89-27d4-4f10-fcac-0667ece13ef5"
   },
   "outputs": [],
   "source": [
    "eval_vectors(\n",
    "    finetuned_preds,\n",
    "    sents_and_labs,\n",
    "    wrd_vec_mode=\"average\",\n",
    "    sentence_emb_mode=\"average_word_vectors\",\n",
    "    plt_xrange=[-0.6, 0.6],\n",
    "    plt_yrange=[-0.6, 0.6],\n",
    "    viz_dims=2,\n",
    "    title_prefix=\"Finetuned model:\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27d63fb",
   "metadata": {
    "id": "p-Pj9zJk-Xnt"
   },
   "source": [
    "## 2. Run with config : \n",
    "* word vec average across 4 layers \n",
    "* calculate distances directly using word movers distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4801c8",
   "metadata": {
    "id": "_WxKK94l-hvM"
   },
   "source": [
    "### 2.1 Pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d7bee2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "yNmE7SIk9IX6",
    "outputId": "85f79ad0-17aa-4ef6-bca5-719e4b3906a1"
   },
   "outputs": [],
   "source": [
    "eval_using_wmd(\n",
    "    pretrained_preds,\n",
    "    sents_and_labs,\n",
    "    wrd_vec_mode=\"average\",\n",
    "    plt_xrange=[-0.6, 0.6],\n",
    "    plt_yrange=[-0.6, 0.6],\n",
    "    title_prefix=\"Pretrained model:\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782d158a",
   "metadata": {
    "id": "gvwS1uRP-koH"
   },
   "source": [
    "### 2.2 Fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd4446c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "pgiH1io19ISz",
    "outputId": "011f1212-0bd3-4d51-bfa6-1193efcc893d"
   },
   "outputs": [],
   "source": [
    "eval_using_wmd(\n",
    "    finetuned_preds,\n",
    "    sents_and_labs,\n",
    "    wrd_vec_mode=\"average\",\n",
    "    plt_xrange=[-0.6, 0.6],\n",
    "    plt_yrange=[-0.6, 0.6],\n",
    "    title_prefix=\"Finetuned model:\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "elm4psir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.15 | packaged by conda-forge | (default, Nov 22 2022, 08:53:40) \n[Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "036f9b356400688fa32ab139d64151f7af42c87240ca002d464048bf8c685a85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
